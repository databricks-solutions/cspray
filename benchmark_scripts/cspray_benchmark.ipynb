{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbac86e6-f6dc-48c1-8454-c0bbfe3cc171",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# install cspray if you have not already\n",
    "#%pip install cspray\n",
    "#%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7c352ff-611a-4cc8-968f-6d05717eac9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from cspray.data import SprayData\n",
    "import cspray as cs\n",
    "import pandas as pd\n",
    "\n",
    "# (optionally) prevent mlflow logging of PCA and kmeans\n",
    "import mlflow\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "# where to save data in Unity Catalog\n",
    "CATALOG = '' \n",
    "SCHEMA = ''\n",
    "\n",
    "# RAM on each worker (only required for read stage -use it to help set read in chunk size optimally)\n",
    "WORKER_RAM : int = 32\n",
    "TOTAL_CORES = spark.sparkContext.defaultParallelism\n",
    "NUM_WORKERS = spark.sparkContext._jsc.sc().getExecutorMemoryStatus().size() - 1\n",
    "CORES_PER_WORKER = TOTAL_CORES // NUM_WORKERS\n",
    "MAX_PARTITIONS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be4ac9ee-560c-4884-85cd-14f55d8d8279",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datasets = [\n",
    " 'b252b015-b488-4d5c-b16e-968c13e48a2c',\n",
    " '0ba636a1-4754-4786-a8be-7ab3cf760fd6',\n",
    " '350237e0-9f48-4cbd-9140-3b44495549f3',\n",
    " 'fd072bc3-2dfb-46f8-b4e3-467cb3223182',\n",
    " '55003f67-c494-46f1-83fb-902745646379',\n",
    " 'ae4f8ddd-cac9-4172-9681-2175da462f2e',\n",
    " '1b9d8702-5af8-4142-85ed-020eb06ec4f6',\n",
    " '80a2c5b6-02e7-4fc0-9f12-179f5247c1bc',\n",
    " 'cd2f23c1-aef1-48ae-8eb4-0bcf124e567d', \n",
    " '21d3e683-80a4-4d9b-bc89-ebb2df513dde', \n",
    " '18e2a8c5-33f7-455e-a58a-b2ba6921db27', \n",
    " '242c6e7f-9016-4048-af70-d631f5eea188',\n",
    " 'ed5d841d-6346-47d4-ab2f-7119ad7e3a35',\n",
    " '576f193c-75d0-4a11-bd25-8676587e6dc2',\n",
    " '7f7faf6b-f11d-4f07-bc1c-188a4472748d',\n",
    " '7b55fe5c-d5c8-48e0-a1a3-54c5b9074f3f',\n",
    " '76150f40-1989-4977-9e23-696e72d59d9e',\n",
    " '43245158-5ae1-4e71-a9a6-67eef49c26bc',\n",
    " '9fcb0b73-c734-40a5-be9c-ace7eea401c9',\n",
    " '518d9049-2a76-44f8-8abc-1e2b59ab5ba1'\n",
    "]\n",
    "root_path = f\"/Volumes/{CATALOG}/{SCHEMA}/raw_h5ad/\"\n",
    "\n",
    "path = [\n",
    "    root_path + d + '.h5ad' for d in datasets\n",
    "]\n",
    "\n",
    "ensembl_reference_df = spark.createDataFrame(cs.utils.get_gene_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69ed2efe-c434-40a3-b7a5-adc0a4549364",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text('BASE_prefix', 'test', 'BASE prefix')\n",
    "BASE_prefix = dbutils.widgets.get('BASE_prefix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d48b7f17-7c0a-4e50-98d2-5105ec52e8d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "sdata = SprayData.from_h5ads(\n",
    "    spark,\n",
    "    path=path, \n",
    "    force_partitioning = 2*spark.sparkContext.defaultParallelism,\n",
    "    chunk_size=int(6_000_000*(WORKER_RAM/16)),\n",
    "    from_raw=True,\n",
    "    fallback_default=False,\n",
    "    broadcast_genes=True,\n",
    "    ensembl_reference_df=ensembl_reference_df,\n",
    ")\n",
    "sdata.to_tables_and_reset(spark, table_base=f'{CATALOG}.{SCHEMA}', join_char=f'.{BASE_prefix}_bronze_')\n",
    "\n",
    "cs.pp.calculate_qc_metrics(sdata)\n",
    "cs.pp.filter_cells(sdata)\n",
    "cs.pp.filter_genes(sdata)\n",
    "cs.pp.apply_samplewise_mt_statistic(sdata)\n",
    "cs.pp.filter_cells_on_mt(sdata)\n",
    "cs.pp.normalize(sdata)\n",
    "cs.pp.log1p_counts(sdata)\n",
    "sdata.to_tables_and_reset(spark, table_base=f'{CATALOG}.{SCHEMA}', join_char=f'.{BASE_prefix}_silver_pp_')\n",
    "\n",
    "cs.pp.calculate_hvg(sdata, n_hvg=1000)\n",
    "sdata.to_tables_and_reset(spark,table_base=f'{CATALOG}.{SCHEMA}', join_char=f'.{BASE_prefix}_silver_hvg_') \n",
    "\n",
    "cs.pp.pca(sdata)\n",
    "sdata.to_tables_and_reset(spark,table_base=f'{CATALOG}.{SCHEMA}', join_char=f'.{BASE_prefix}_silver_pca_', subset=['obs'])\n",
    "\n",
    "scores_pdf = cs.tl.kmeans(sdata, ks=[2,3,4,5])\n",
    "sdf_rank = cs.tl.rank_marker_genes(sdata, fc_cutoff=0.15)\n",
    "sdata.to_tables_and_reset(spark,table_base=f'{CATALOG}.{SCHEMA}', join_char=f'.{BASE_prefix}_silver_end_')\n",
    "\n",
    "# not required as benchmarking v scanpy\n",
    "# cs.tl.as_gold_mart_data(sdata)\n",
    "# sdata.to_tables_and_reset(spark,table_base=f'{CATALOG}.{SCHEMA}', join_char='.gold_') \n",
    "\n",
    "\n",
    "# not required as benchmarking v scanpy\n",
    "# cs.tl.as_gold_mart_data(sdata)\n",
    "# sdata.to_tables_and_reset(spark,table_base=f'{CATALOG}.{SCHEMA}', join_char='.gold_') \n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"Total time: {(t1-t0)} seconds\")\n",
    "print(f\"Total time: {(t1-t0)/60.} minutes\")\n",
    "print(f\"Total time: {(t1-t0)/60./60.} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "834ba336-c6c6-4fe0-9e3c-f0fcc688c6c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.jobs.taskValues.set(key=\"execution_time\", value= t1 - t0)\n",
    "\n",
    "ex_time = t1-t0\n",
    "dbutils.notebook.exit(\"{:.3f}\".format(ex_time))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "cspray_benchmark",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
